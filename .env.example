# LLM credential and endpoint configuration for verl-plus.
# Copy this file to .env and fill in your actual API keys.

# OpenAI API Configuration
OPENAI_BASE_URL=https://yunwu.zeabur.app/v1
OPENAI_MODEL_NAME=gpt-4o-mini
OPENAI_API_KEY=your-openai-api-key-here

# Weights & Biases Configuration
WANDB_API_KEY=your-wandb-api-key-here
WANDB_MODE=online

# Optional: Additional OpenAI API Keys (if needed)
# OPENAI_API_KEY_1=your-second-openai-key-here
# OPENAI_API_KEY_2=your-third-openai-key-here

# Dataset Paths (customize as needed)
DATA_ROOT=/data/wzh/wzh/datasets/MM-EUREKA/verl
TRAIN_PARQUET=${DATA_ROOT}/train.parquet
VAL_PARQUET=${DATA_ROOT}/val.parquet

# Model Paths (customize as needed)
MODEL_PATH=/data/wzh/wzh/models/qwen/Qwen2.5-VL-3B-Instruct
OUTPUT_DIR=/data/wzh/wzh/rl/verl-plus/outputs/mm_eruka_qwen25vl_3b_caption
LOG_DIR=/data/wzh/wzh/rl/verl-plus/logs

# CUDA Configuration
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
TOKENIZERS_PARALLELISM=true
NCCL_DEBUG=WARN

# Cache Configuration
QUESTION_CACHE_PATH=${OUTPUT_DIR}/caption_question_cache.jsonl
PRECOMPUTE_QUESTION_CACHE=true